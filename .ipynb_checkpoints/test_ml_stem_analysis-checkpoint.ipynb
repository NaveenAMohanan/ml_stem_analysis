{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R.O.C.K.S (RedCarpet Open Code and Kraft Series) task implemention Test cases\n",
    "Naveen A Mohanan 27/4/2018\n",
    "\n",
    "Email :menaveenam@gmail.com or naveen.am@yahoo.com\n",
    "\n",
    "Mno : 9599131811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytest file for ml_stem_analysis.ipynb (all inline converted into functions)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artical reffered to https://semaphoreci.com/community/tutorials/testing-python-applications-with-pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exl_to_df():  \n",
    "    data_read = pd.read_excel('2010 Federal STEM Education Inventory Data Set.xls',header =1)\n",
    "    #print (\"Total (rows,col)=\",data_read.shape,\"\\nSAMPLE\")\n",
    "    #print(data_read.head(5))\n",
    "    return(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exl_to_df():\n",
    "    if not isinstance(exl_to_df(),pd.DataFrame):\n",
    "        raise TypeError('Not a dataframe')\n",
    "    if not exl_to_df().shape==(253,256):\n",
    "        print(\"Does not have correct no of rows and col.\")\n",
    "    assert exl_to_df().columns[0] == 'Index Number'\n",
    "    print(\"Read file is correct \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file is correct \n"
     ]
    }
   ],
   "source": [
    "test_exl_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_per_change():\n",
    "    data_read = exl_to_df()\n",
    "    per_change_df = pd.DataFrame()\n",
    "    per_change_df['Index Number'] = data_read['Index Number']\n",
    "    per_change_df['% change'] = ((data_read['C2) Funding FY2009'] - data_read['C1) Funding FY2008'])/data_read['C1) Funding FY2008'])\n",
    "    per_change_df['Tag'] = np.where(per_change_df['% change'] > 0, 1, 0)\n",
    "    return(per_change_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cal_per_change():\n",
    "    assert cal_per_change()[cal_per_change().columns[2]].isnull().sum() == 0\n",
    "    print(\"calculated tag is correctly assigned to all values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated tag is correctly assigned to all values\n"
     ]
    }
   ],
   "source": [
    "test_cal_per_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_per_change():\n",
    "    data_read = exl_to_df()\n",
    "    per_change_df = cal_per_change()\n",
    "    per_change_df = data_read.merge(per_change_df,on='Index Number')\n",
    "    return(per_change_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_merge_per_change():\n",
    "    assert isinstance(merge_per_change(),pd.DataFrame)\n",
    "    assert merge_per_change().shape==(253,258)\n",
    "    assert merge_per_change().columns[0] == 'Index Number'\n",
    "    assert merge_per_change().columns[257] == 'Tag'\n",
    "    print(\"File merged correctly \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File merged correctly \n"
     ]
    }
   ],
   "source": [
    "test_merge_per_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    for i in attribute_list:\\n        if((i == 'C1) Funding FY2008') or (i == 'C2) Funding FY2009') or (i == 'C3) Funding FY2010') ):\\n            continue\\n        \\n        else:\\n            t=data_read[i].dropna()\\n            fig,ax=plt.subplots()\\n            plt.hist(t)\\n            ax.set_xlabel(i)\\n            ax.set_ylabel('count')\\n            plt.show(ax)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot():\n",
    "    data_read = exl_to_df()\n",
    "    attribute_list = data_read.columns.tolist()\n",
    "    return(attribute_list)\n",
    "#Not printing the graph here\n",
    "'''\n",
    "    for i in attribute_list:\n",
    "        if((i == 'C1) Funding FY2008') or (i == 'C2) Funding FY2009') or (i == 'C3) Funding FY2010') ):\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            t=data_read[i].dropna()\n",
    "            fig,ax=plt.subplots()\n",
    "            plt.hist(t)\n",
    "            ax.set_xlabel(i)\n",
    "            ax.set_ylabel('count')\n",
    "            plt.show(ax)\n",
    "'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plot():\n",
    "    assert plot()[0] == 'Index Number'\n",
    "    assert plot()[254] == 'Y5) Expert Review Type'\n",
    "    print(\"Correct 1st and 2nd last col. Read from correct file will genrate correct graphs\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 1st and 2nd last col. Read from correct file will genrate correct graphs\n"
     ]
    }
   ],
   "source": [
    "test_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating mutual_info_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "label=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string fields to no for analysis \n",
    "def mutual_info_score():\n",
    "    per_change_df = merge_per_change()\n",
    "    T = per_change_df\n",
    "    t = np.array(per_change_df['Tag']).ravel()\n",
    "    for i in T:      \n",
    "        try:\n",
    "            T[i]=label.fit_transform(T[i])\n",
    "        except:\n",
    "            T[i]=label.fit_transform(T[i].astype('str'))\n",
    "\n",
    "    variable=[]\n",
    "    v_score=[]\n",
    "    # calculating mutual_info_score\n",
    "    for i in T:\n",
    "        if((i == 'C1) Funding FY2008') or (i == 'C2) Funding FY2009') or (i == 'C3) Funding FY2010') ):\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            x=T[i].ravel()\n",
    "            score=metrics.mutual_info_score(x,t)\n",
    "            v_score.append(score)\n",
    "            variable.append(i)  \n",
    "\n",
    "    Mutual_info=pd.DataFrame({'Variables':variable,'MI Score':v_score})\n",
    "    \n",
    "    return(Mutual_info)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mutual_info_score():\n",
    "    assert mutual_info_score().columns[0] == 'MI Score'\n",
    "    assert mutual_info_score().columns[1] == 'Variables'\n",
    "    assert mutual_info_score().shape==(255,2)\n",
    "    print(\"Mutual info data frame created succefully with col MI Score and Variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual info data frame created succefully with col MI Score and Variables\n"
     ]
    }
   ],
   "source": [
    "test_mutual_info_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost():\n",
    "    T = merge_per_change()\n",
    "    for i in T:      \n",
    "        try:\n",
    "            T[i]=label.fit_transform(T[i])\n",
    "        except:\n",
    "            T[i]=label.fit_transform(T[i].astype('str'))\n",
    "    # matrix of features and targer \n",
    "    X = T.iloc[:, 1:257].values\n",
    "    y = T.iloc[:, 257].values\n",
    "\n",
    "    #Divide data into train & test samples. (70-30 split)\n",
    "    \n",
    "    X_train, X_test, y_train,y_test = train_test_split(X, y, test_size = 0.3,random_state = 0 )\n",
    "\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    dtest_predprob = classifier.predict_proba(X_test)[:,1]\n",
    "    print(\"Roc score = \",metrics.roc_auc_score(y_test, dtest_predprob))\n",
    "    \n",
    "    return(X,y,cm,metrics.roc_auc_score(y_test, dtest_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgboost():\n",
    "    X,y,cm,roc = xgboost()\n",
    "    assert isinstance(X,np.ndarray)\n",
    "    assert isinstance(y,np.ndarray)\n",
    "    print(\"Both the features and taget are correctly formated to put into classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0]\n",
      " [ 0 44]]\n",
      "Roc score =  1.0\n",
      "Both the features and taget are correctly formated to put into classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naveen\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_xgboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further more every assert stmt can be expanded using if to provide more in depth error detatils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exl_to_df_type1():\n",
    "    assert isinstance(exl_to_df(),pd.DataFrame)\n",
    "    assert exl_to_df().shape==(253,256)\n",
    "    assert exl_to_df().columns[0] == 'Index Number'\n",
    "    print(\"Read file is correct \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exl_to_df_type2():\n",
    "    if not isinstance(exl_to_df(),pd.DataFrame):\n",
    "        raise TypeError('Not a dataframe')\n",
    "    if not exl_to_df().shape==(253,256):\n",
    "        print(\"Does not have correct no of rows and col.\")\n",
    "    if not exl_to_df().columns[0] == 'Index Number':\n",
    "        print(\"Does not have correct first col name check ip file\")\n",
    "    print(\"Read file is correct \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file is correct \n",
      "Read file is correct \n"
     ]
    }
   ],
   "source": [
    "test_exl_to_df_type1()\n",
    "test_exl_to_df_type2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
